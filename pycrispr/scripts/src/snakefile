import glob
import os
import pandas as pd
import sys
from pathlib import Path
import click


####LOADING VARIABLES####

#load config file
configfile: "experiment.yaml"

#load variables
library = config["library"]
fasta = config["lib_info"][library]["fasta"]

#check if fasta file is correct (same amount of lines starting with and without >)
with open(fasta, "r") as f:
    
    lines = f.readlines()
    
    lines_seq = [x for x in lines if not x.startswith(">")]
    lines_name = [x for x in lines if x.startswith(">")]
    
    if len(lines_seq) != len(lines_name):
        
        click.secho("ERROR: Fasta file is not correct (number of name and sequence lines does not match)...", fg="red")
        
        sys.exit(1)

#get gene count from sgRNA fasta file
f = open(fasta,'r')
lines = f.readlines()
gene_number = len(set([x.split("_")[0] for x in lines[::2]]))

#prepare HISAT2 index name
index = os.path.basename(fasta).split(".",1)[0]
index = f"index_{index}/index_{index}"

#get sgRNA length
sg_length = config["lib_info"][library]["sg_length"]

#get vector sequence to remove (if any)
try:
    
    vector = config["lib_info"][library]["vector"]

    #check if vector is DNA sequence or empty
    if vector == "":

        cut_arg = f"-l {sg_length}"

    elif not set(vector.lower()).issubset(set("atcg")):
        
        click.secho(f"ERROR: vector sequence ({vector}) for {library} is not a DNA sequence...", fg="red")
        
        sys.exit(1)
    
    else:
        
        cut_arg = f"-a {vector}" 
    
except KeyError:
    
    cut_arg = f"-l {sg_length}"


#check if stats should be skipped
skip_stats = config["stats"]["skip"]

#load rename info
try:
    
    csv = pd.read_csv("rename.csv")

except FileNotFoundError:
    
    click.secho("WARNING: No rename.csv file found!\nAssuming files have been renamed already...", fg="orange")

    Path.touch("rename.done")

#check if read files need to be renamed
if not os.path.exists("rename.done"):
    
    OLD_FILES = csv["old"].tolist()
    NEW_FILES = csv["new"].tolist()

    #create sample names
    SAMPLES = [x.replace(".fq.gz","") for x in NEW_FILES]

else:
    
    #create sample names
    SAMPLES = [os.path.basename(x).replace(".fq.gz","") for x in glob.glob("reads/*fq.gz")]
    #remove any pre-existing trimmed fq files from this list
    SAMPLES = [x for x in SAMPLES if not "_trimmed" in x]

#load stats comparisons
try:

    COMPARISONS = pd.read_csv("stats.csv")

    COMPARISONS = (COMPARISONS["test"] + "_vs_" + COMPARISONS["control"]).tolist()

    COMPARISONS = [x.replace(";","-") for x in COMPARISONS]

    #remove comparisons with pooled control samples (not supported by BAGEL2)
    B_COMPARISONS = [x for x in COMPARISONS if not "-" in x.split("_vs_")[1]]

except FileNotFoundError:

    click.secho("WARNING: No stats.csv file found!\nSkipping statistical analysis of sgRNAs...", fg="orange")



#set targets for target rule
TARGETS =   ["md5sums/md5sums.txt",
            expand("qc/fastqc/{sample}.html", sample=SAMPLES),
            expand("qc/fastqc/{sample}_fastqc.zip", sample=SAMPLES),
            expand("reads/{sample}_trimmed.fq.gz", sample=SAMPLES),
            "qc/multiqc.html",
            "count/alignment-rates.pdf",
            "count/sequence-coverage.pdf",
            f"{index}.1.ht2",
            f"{index}.2.ht2",
            f"{index}.3.ht2",
            f"{index}.4.ht2",
            f"{index}.5.ht2",
            f"{index}.6.ht2",
            f"{index}.7.ht2",
            f"{index}.8.ht2",
            "qc/gini-index.pdf",
            "qc/sample-correlation.pdf",
            "qc/missed-rgrnas.pdf",
            ]

if skip_stats != "mageck" and skip_stats !="both":
    
    #extend target rule with MAGecK targets     
    TARGETS.extend([
        expand("mageck/{comparison}/{comparison}.gene_summary.txt", comparison=COMPARISONS),
        expand("mageck/{comparison}/{comparison}.sgrna_summary.txt", comparison=COMPARISONS),
        expand("mageck_plots/{comparison}/{comparison}.volcano.pdf", comparison=COMPARISONS),
        expand("mageck_plots/{comparison}/{comparison}.dot_pos.pdf", comparison=COMPARISONS),
        expand("mageck_plots/{comparison}/{comparison}.dot_neg.pdf", comparison=COMPARISONS),
        expand("mageck_plots/{comparison}/{comparison}.sgrank.pdf", comparison=COMPARISONS),
        
    ])

    if gene_number > 15000: #only perform GO analysis on whole genome libraries (assume that number of genes in library is > 15k)
            
            TARGETS.extend([
                #expand("GO_analysis/{comparison}/depletion/GO_analysis.xlsx", comparison=COMPARISONS),
                #expand("GO_analysis/{comparison}/depletion/dot_plot.pdf", comparison=COMPARISONS),
                #expand("GO_analysis/{comparison}/enrichment/GO_analysis.xlsx", comparison=COMPARISONS),
                #expand("GO_analysis/{comparison}/enrichment/dot_plot.pdf", comparison=COMPARISONS),
                expand("mageck_go_analysis/{comparison}/", comparison=COMPARISONS),
            ])

if skip_stats != "bagel2" and skip_stats !="both":
    
    #extend target rule with BAGEL2 targets
    TARGETS.extend([
        "bagel2_software/",
        "count/counts-aggregated-bagel2.tsv",
        expand("bagel2/{bcomparison}/{bcomparison}.foldchange", bcomparison=B_COMPARISONS),
        expand("bagel2/{bcomparison}/{bcomparison}.bf", bcomparison=B_COMPARISONS),
        expand("bagel2/{bcomparison}/{bcomparison}.pr", bcomparison=B_COMPARISONS),
        expand("bagel2_plots/{bcomparison}/{bcomparison}.bf.pdf", bcomparison=B_COMPARISONS),
        expand("bagel2_plots/{bcomparison}/{bcomparison}.pr.pdf", bcomparison=B_COMPARISONS),
    ])



####SNAKEMAKE RULES####

#report location
report: "report/report.rst"

#rules to be run on login node instead of compute node when running on HPC (only very small jobs)
if skip_stats != "none" and skip_stats != "bagel2":

    localrules: all, rename, aggregated_counts, plot_alignment_rate, plot_coverage, plot_bf, plot_pr

else:

    localrules: all, rename, aggregated_counts, plot_alignment_rate, plot_coverage


#extend TARGETS with renamed files if required
if not os.path.exists("rename.done"):
    
    TARGETS.extend(expand("reads/{new_file}", new_file=NEW_FILES)),
    TARGETS.append("rename.done")

#set target rule
rule all:
    input:
        TARGETS



if not os.path.exists("rename.done"):
    
    rule check_md5_sums:
        output:
            "md5sums/md5sums.txt"
        conda:
            "envs/count.yaml"
        script:
            "scripts/check_md5_sums.py"

    rule rename:
        input:
            reads=expand("reads/{old_file}", old_file=OLD_FILES),
            md5sum="md5sums/md5sums.txt"
        output:
            f=expand("reads/{new_file}", new_file=NEW_FILES),
            t=touch("rename.done"),
        run:
            for o,n in zip(list({input.reads})[0], list({output.f})[0]):
                os.rename(o,n)


rule fastqc:
    input:
        "reads/{sample}_trimmed.fq.gz"
    output:
        html="qc/fastqc/{sample}.html",
        zip="qc/fastqc/{sample}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file
    params:
        extra = "--quiet"
    log:
        "logs/fastqc/{sample}.log"
    threads: config["resources"]["fastqc"]["cpu"]
    resources:
        runtime=config["resources"]["fastqc"]["time"]
    wrapper:
        "v1.31.1/bio/fastqc"


rule multiqc:
    input:
        expand("qc/fastqc/{sample}_fastqc.zip", sample=SAMPLES)
    output:
        report("qc/multiqc.html", caption="report/multiqc.rst", category="MultiQC analysis of fastq files")
    params:
        extra="",  # Optional: extra parameters for multiqc.
        use_input_files_only=True, # Optional, use only a.txt and don't search folder samtools_stats for files
    resources:
        runtime=config["resources"]["fastqc"]["time"]
    log:
        "logs/multiqc/multiqc.log"
    wrapper:
        "v1.31.1/bio/multiqc"


rule trim:
    input:
        "reads/{sample}.fq.gz"
    output:
        temp("reads/{sample}_trimmed.fq.gz"),
    params:
        cut_arg=cut_args,
        lt=config["lib_info"][library]["left_trim"],
    threads: config["resources"]["trim"]["cpu"]
    conda:
        "envs/trim.yaml"
    log:
        "logs/trim/{sample}.log",
    resources:
        runtime=config["resources"]["trim"]["time"]
    shell:
        "cutadapt -j {threads} --quality-base 33 -u {params.lt} {cut_args} {input} > {output} 2> {log}"


rule hisat2_index: 
    output:
        f"{index}.1.ht2",
        f"{index}.2.ht2",
        f"{index}.3.ht2",
        f"{index}.4.ht2",
        f"{index}.5.ht2",
        f"{index}.6.ht2",
        f"{index}.7.ht2",
        f"{index}.8.ht2",
    threads: config["resources"]["count"]["cpu"]
    resources:
        runtime=config["resources"]["count"]["time"]
    log:
        "logs/hisat2_index.log"
    conda:
        "envs/count.yaml"
    shell:
        "hisat2-build -p {threads} {fasta} {index} 2> {log}"


rule count:
    input: 
        fq="reads/{sample}_trimmed.fq.gz",
        idx=f"{index}.1.ht2",
    output:
        "count/{sample}.guidecounts.txt"
    params:
        mm=config["mismatch"],
    threads: config["resources"]["count"]["cpu"]
    resources:
        runtime=config["resources"]["count"]["time"]
    log:
        "logs/count/{sample}.log"
    conda:
        "envs/count.yaml"
    shell:
        "zcat {input.fq} | hisat2 --no-hd -p {threads} -t -N {params.mm} -x {index} - 2> {log} | "
        "sed '/XS:/d' | cut -f3 | sort | uniq -c | sed 's/^ *//' | sed '1d' > {output}"


rule aggregated_counts:
    input:
        files=expand("count/{sample}.guidecounts.txt", sample=SAMPLES)
    output:
        "count/counts-aggregated.tsv"
    params:
        fa=fasta,
    script:
        "scripts/join.py"


if skip_stats != "mageck" and skip_stats !="both":

    #check if control genes are specified for generating null distribution of RRA scores
    if config["stats"]["mageck_control_genes"] == "all": #use all genes as controls

        control = ""

    else: #use genes from file set in config

        file = config["stats"]["mageck_control_genes"]

        control = f"--control-gene {file}" 


    rule mageck:
        input: 
            "count/counts-aggregated.tsv"
        output:
            "mageck/{comparison}/{comparison}_summary.Rnw",
            report("mageck/{comparison}/{comparison}.gene_summary.txt", caption="report/mageck.rst", category="MAGeCK"),
            "mageck/{comparison}/{comparison}.log",
            "mageck/{comparison}/{comparison}.R",
            "mageck/{comparison}/{comparison}.sgrna_summary.txt",
            "mageck/{comparison}/{comparison}.normalized.txt"
        params:
            control=control,
            extra=config["stats"]["extra_mageck_arguments"],
        resources:
            runtime=config["resources"]["stats"]["time"]
        conda:
            "envs/stats.yaml"
        log:
            "logs/mageck/{comparison}.log"
        shell:
            '''
            mageck test --normcounts-to-file -k {input} -t $(echo "{wildcards.comparison}" | awk -F '_vs_' '{{print $1}}' | sed 's/-/,/') -c $(echo "{wildcards.comparison}" | awk -F '_vs_' '{{print $2}}' | sed 's/-/,/' ) -n mageck/{wildcards.comparison}/{wildcards.comparison} {params.control} {params.extra} 2> {log}
            '''

    #create normalised count table (normalised to total read count)
    rule normalise_count_table:
        input:
            counts="count/counts-aggregated.tsv"
        output:
            norm_counts="count/counts-aggregated_normalised.csv"
        run:
            df = pd.read_table(input.counts)
            column_range = range(2,len(df.columns))
            for i in column_range:
                column_sum = df.iloc[:,i].sum()
                df.iloc[:,i] = df.iloc[:,i] / column_sum * 1E8
                df.iloc[:,i] = df.iloc[:,i].astype(int)
            df.to_csv(output.norm_counts,
                    index = False,
                    header = True)
            

    rule mageck_plots:
        input:
            "mageck/{comparison}/{comparison}.gene_summary.txt",
            "mageck/{comparison}/{comparison}.sgrna_summary.txt"
        output:
            volc=report("mageck_plots/{comparison}/{comparison}.volcano.pdf", caption="report/volcano.rst", category="MAGeCK plots", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "volcano plot"}),
            dot_pos=report("mageck_plots/{comparison}/{comparison}.dot_pos.pdf", caption="report/dot-plot_pos.rst", category="MAGeCK plots", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "dot plot enriched genes"}),
            dot_neg=report("mageck_plots/{comparison}/{comparison}.dot_neg.pdf", caption="report/dot-plot_neg.rst", category="MAGeCK plots", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "dot plot depleted genes"}),
            rank=report("mageck_plots/{comparison}/{comparison}.sgrank.pdf", caption="report/sgrank.rst", category="MAGeCK plots", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "sgRNA rank"}),
        params:
            spc=config["lib_info"][library]["species"],
            fdr=config["stats"]["fdr"],
        resources:
            runtime=config["resources"]["stats"]["time"]
        log:
            "logs/mageck_plots/{comparison}.log"
        conda:
            "envs/r-plots.yaml"
        script:
            "scripts/mageck_plots.R"
    

    if gene_number > 15000: #only perform GO analysis on whole genome libraries (assume that number of genes in library is > 15k)

        rule mageck_go_analysis:
            input:
                "mageck/{comparison}/{comparison}.gene_summary.txt",
            output:
                directory("mageck_go_analysis/{comparison}/"),
                #go_x_neg=report("GO_analysis/{comparison}/depletion/GO_analysis.xlsx", caption="report/GO_analysis.rst", category="GO analysis", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "GO analysis"}),
                #go_p_neg=report("GO_analysis/{comparison}/depletion/dot_plot.pdf", caption="report/GO_analysis_plot.rst", category="GO analysis", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "GO analysis"}),
                #go_x_pos=report("GO_analysis/{comparison}/enrichment/GO_analysis.xlsx", caption="report/GO_analysis.rst", category="GO analysis", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "GO analysis"}),
                #go_p_pos=report("GO_analysis/{comparison}/enrichment/dot_plot.pdf", caption="report/GO_analysis_plot.rst", category="GO analysis", subcategory="{comparison}", labels={"Comparison":"{comparison}","Figure": "GO analysis"}),
            params:
                spc=config["lib_info"][library]["species"],
                fdr=config["stats"]["fdr"],
            resources:
                runtime=config["resources"]["stats"]["time"]
            log:
                "logs/mageck_go_analysis/{comparison}.log"
            conda:
                "envs/r-plots.yaml"
            script:
                "scripts/mageck_go_analysis.R"


if skip_stats != "bagel2" and skip_stats !="both":
    
    rule install_bagel2:
        output:
            directory("bagel2_software/"),
        log:
            "logs/bagel2/install.log"
        shell:
            "git clone https://github.com/hart-lab/bagel.git {output} 2> {log}"
        

    rule convert_count_table:
        input:
            "count/counts-aggregated.tsv"
        output:
            "count/counts-aggregated-bagel2.tsv"
        params:
            fa=fasta,
        resources:
            runtime=config["resources"]["stats"]["time"]
        conda:
            "envs/stats.yaml"
        script:
            "scripts/convert_count_table.py"


    rule bagel2fc:
        input:
            "bagel2_software/",
            "count/counts-aggregated-bagel2.tsv",
        output:
            "bagel2/{bcomparison}/{bcomparison}.foldchange"
        resources:
            runtime=config["resources"]["stats"]["time"]
        conda:
            "envs/stats.yaml"
        log:
            "logs/bagel2/fc/{bcomparison}.log"
        script:
            "scripts/bagel2fc.py"


    rule bagel2bf:
        input:
            "bagel2_software/",
            "bagel2/{bcomparison}/{bcomparison}.foldchange",
        output:
            "bagel2/{bcomparison}/{bcomparison}.bf"
        params:
            species=config["lib_info"][library]["species"],
        resources:
            runtime=config["resources"]["stats"]["time"]
        conda:
            "envs/stats.yaml"
        log:
            "logs/bagel2/bf/{bcomparison}.log"
        script:
            "scripts/bagel2bf.py"


    rule bagel2pr:
        input:
            "bagel2_software/",
            "bagel2/{bcomparison}/{bcomparison}.bf",
        output:
            report("bagel2/{bcomparison}/{bcomparison}.pr", caption="report/bagel2.rst", category="BAGEL2")
        params:
            species=config["lib_info"][library]["species"]
        resources:
            runtime=config["resources"]["stats"]["time"]
        conda:
            "envs/stats.yaml"
        log:
            "logs/bagel2/pr/{bcomparison}.log"
        script:
            "scripts/bagel2pr.py"


    rule plot_bf:
        input:
            "bagel2/{bcomparison}/{bcomparison}.bf"
        output:
            report("bagel2_plots/{bcomparison}/{bcomparison}.bf.pdf", caption="report/bagel2_plots.rst", category="BAGEL2 plots", subcategory="{bcomparison}", labels={"Comparison":"{bcomparison}", "Figure":"BF plot"})
        conda:
            "envs/stats.yaml"
        script:
            "scripts/plot_bf.py"


    rule plot_pr:
        input:
            "bagel2/{bcomparison}/{bcomparison}.pr"
        output:
            report("bagel2_plots/{bcomparison}/{bcomparison}.pr.pdf", caption="report/bagel2_plots.rst", category="BAGEL2 plots", subcategory="{bcomparison}", labels={"Comparison":"{bcomparison}", "Figure":"Precision-recall plot"})
        conda:
            "envs/stats.yaml"
        script:
            "scripts/plot_pr.py"


rule plot_alignment_rate:
    input:
        expand("logs/count/{sample}.log", sample=SAMPLES)
    output:
        report("count/alignment-rates.pdf", caption="report/alignment-rates.rst", category="Alignment rates")
    params:
        name="plot_alignment_rate",
        yaml="envs/plot_settings.yaml"
    script:
        "scripts/plot.py"


rule plot_coverage:
    input:
        "count/counts-aggregated.tsv"
    params:
        name="plot_coverage",
        fa=fasta,
    output:
        report("count/sequence-coverage.pdf", caption="report/plot-coverage.rst", category="Sequence coverage")
    script:
        "scripts/plot.py"


rule plot_gini_index:
    input:
        "count/counts-aggregated.tsv"
    output:
        report("qc/gini-index.pdf", caption="report/gini-index.rst", category="Gini index")
    params:
        yaml="envs/plot_settings.yaml"
    log:
        "logs/gini-index.log"
    conda:
        "envs/r-plots.yaml"
    script:
        "scripts/plot_gini_index.R"


rule plot_sample_correlation:
    input:
        "count/counts-aggregated_normalised.csv"
    output:
        report("qc/sample-correlation.pdf", caption="report/sample-correlation.rst", category="Sample correlation")
    log:
        "logs/sample-correlation.log"
    conda:
        "envs/r-plots.yaml"
    script:
        "scripts/sample_correlation.R"


rule plot_missed_rgrnas:
    input:
        "count/counts-aggregated.tsv"
    output:
        report("qc/missed-rgrnas.pdf", caption="report/missed-rgrnas.rst", category="Missed sgRNAs")
    params:
        yaml="envs/plot_settings.yaml"
    log:
        "logs/missed-rgrnas.log"
    conda:
        "envs/r-plots.yaml"
    script:
        "scripts/missed_sgrnas.R"


#save snakemake terminal output to log file
snake_log = "logs/snakemake.log"

onsuccess:
    
    shell("cp -v {log} {snake_log}")
    click.secho("Analysis finished successfully!", fg="green")

onerror:
    
    shell("cp -v {log} {snake_log}")
    click.secho(f"Analysis (partly) failed...\nCheck {snake_log} for details", fg="red")





